{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from stn import spatial_transformer_network as transformer\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.activations as ac\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rescale=1 / 255,validation_split=0.2)\n",
    "test = ImageDataGenerator(rescale=1 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(150,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3282 images belonging to 49 classes.\n",
      "Found 795 images belonging to 49 classes.\n",
      "Found 1919 images belonging to 49 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train.flow_from_directory(\"../database/sharpness1reduce/train\",\n",
    "                                          target_size=image_size,\n",
    "                                          class_mode=\"categorical\",\n",
    "                                          subset=\"training\",\n",
    "                                          \n",
    "                                         )\n",
    "valid_dataset = train.flow_from_directory(\"../database/sharpness1reduce/train\",\n",
    "                                          target_size=image_size,\n",
    "                                          class_mode=\"categorical\",                                          \n",
    "                                          subset=\"validation\")\n",
    "\n",
    "test_dataset = test.flow_from_directory(\"../database/sharpness1reduce/test\",\n",
    "                                        target_size=image_size,                                       \n",
    "                                        class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 32)      4736      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      25632     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 148, 148, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 74, 74, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 74, 74, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 72, 72, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 36, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 36, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 34, 34, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 17, 17, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 5, 5, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 49)                3185      \n",
      "=================================================================\n",
      "Total params: 10,682,673\n",
      "Trainable params: 10,678,705\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "    \n",
    "model.add(tf.keras.Input(shape=(150, 150, 3)))\n",
    "model.add(tf.keras.layers.Conv2D(32,(7, 7),padding=\"same\",activation=\"relu\"))       \n",
    "model.add(tf.keras.layers.Conv2D(32,(5, 5),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(32,(3, 3),activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2 ,2)))\n",
    "        \n",
    "model.add(tf.keras.layers.Conv2D(64,(3, 3), padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3, 3), padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3, 3),activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2 ,2)))\n",
    "        \n",
    "model.add(tf.keras.layers.Conv2D(128,(3, 3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(128,(3, 3),padding=\"same\",activation=\"relu\")) \n",
    "model.add(tf.keras.layers.Conv2D(128,(3, 3),activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(256,(3, 3), padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(256,(3, 3), padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(256,(3, 3),activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(512,(3, 3), padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(512,(3, 3), padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(512,(3, 3),activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2 ,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(1024,kernel_regularizer=l2(0.005),bias_regularizer=l2(0.005)))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.BatchNormalization()),\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(512,kernel_regularizer=l2(0.005),bias_regularizer=l2(0.005)))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "        \n",
    "model.add(tf.keras.layers.Dense(256,kernel_regularizer=l2(0.005),bias_regularizer=l2(0.005)))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "        \n",
    "model.add(tf.keras.layers.Dense(128))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64))\n",
    "model.add(tf.keras.layers.ReLU())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(tf.keras.layers.Dense(49, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 40 steps, validate for 25 steps\n",
      "Epoch 1/250\n",
      "40/40 [==============================] - 10s 249ms/step - loss: 13.7016 - accuracy: 0.0227 - val_loss: 100.3314 - val_accuracy: 0.0642\n",
      "Epoch 2/250\n",
      "40/40 [==============================] - 6s 147ms/step - loss: 11.0072 - accuracy: 0.0600 - val_loss: 59.2572 - val_accuracy: 0.1119\n",
      "Epoch 3/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 9.8208 - accuracy: 0.1063 - val_loss: 28.1262 - val_accuracy: 0.1145\n",
      "Epoch 4/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 8.8333 - accuracy: 0.1319 - val_loss: 8.9109 - val_accuracy: 0.1635\n",
      "Epoch 5/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 8.1062 - accuracy: 0.1297 - val_loss: 7.7446 - val_accuracy: 0.1371\n",
      "Epoch 6/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 7.4915 - accuracy: 0.1422 - val_loss: 7.3002 - val_accuracy: 0.1447\n",
      "Epoch 7/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 6.9661 - accuracy: 0.1682 - val_loss: 9.6389 - val_accuracy: 0.1572\n",
      "Epoch 8/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 6.4816 - accuracy: 0.1793 - val_loss: 6.1389 - val_accuracy: 0.1950\n",
      "Epoch 9/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 6.0751 - accuracy: 0.1906 - val_loss: 7.0249 - val_accuracy: 0.0377\n",
      "Epoch 10/250\n",
      "40/40 [==============================] - 4s 103ms/step - loss: 5.7988 - accuracy: 0.1880 - val_loss: 29.6725 - val_accuracy: 0.1119\n",
      "Epoch 11/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 5.5532 - accuracy: 0.1937 - val_loss: 5.7613 - val_accuracy: 0.0994\n",
      "Epoch 12/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 5.2421 - accuracy: 0.2141 - val_loss: 6.5240 - val_accuracy: 0.0377\n",
      "Epoch 13/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 4.8771 - accuracy: 0.2562 - val_loss: 7.3916 - val_accuracy: 0.0390\n",
      "Epoch 14/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 4.7532 - accuracy: 0.2362 - val_loss: 4.5949 - val_accuracy: 0.2830\n",
      "Epoch 15/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 4.5299 - accuracy: 0.2496 - val_loss: 6.2314 - val_accuracy: 0.0390\n",
      "Epoch 16/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 4.4596 - accuracy: 0.2204 - val_loss: 6.4437 - val_accuracy: 0.1786\n",
      "Epoch 17/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 4.1780 - accuracy: 0.2477 - val_loss: 47.6696 - val_accuracy: 0.0403\n",
      "Epoch 18/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 4.0497 - accuracy: 0.2539 - val_loss: 4.5087 - val_accuracy: 0.1421\n",
      "Epoch 19/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.9147 - accuracy: 0.2457 - val_loss: 4.0494 - val_accuracy: 0.2629\n",
      "Epoch 20/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.7847 - accuracy: 0.2599 - val_loss: 4.4074 - val_accuracy: 0.1497\n",
      "Epoch 21/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.7023 - accuracy: 0.2528 - val_loss: 7.0712 - val_accuracy: 0.1182\n",
      "Epoch 22/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 3.5645 - accuracy: 0.2578 - val_loss: 3.3426 - val_accuracy: 0.2843\n",
      "Epoch 23/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.4714 - accuracy: 0.2570 - val_loss: 4.6626 - val_accuracy: 0.0780\n",
      "Epoch 24/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.4370 - accuracy: 0.2433 - val_loss: 3.5468 - val_accuracy: 0.2214\n",
      "Epoch 25/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.3243 - accuracy: 0.2602 - val_loss: 4.5248 - val_accuracy: 0.0403\n",
      "Epoch 26/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.2306 - accuracy: 0.2765 - val_loss: 2.8721 - val_accuracy: 0.3321\n",
      "Epoch 27/250\n",
      "40/40 [==============================] - 4s 103ms/step - loss: 3.1453 - accuracy: 0.2844 - val_loss: 5.3174 - val_accuracy: 0.2126\n",
      "Epoch 28/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 3.1544 - accuracy: 0.2570 - val_loss: 3.2714 - val_accuracy: 0.2453\n",
      "Epoch 29/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 3.0287 - accuracy: 0.2701 - val_loss: 3.4037 - val_accuracy: 0.1824\n",
      "Epoch 30/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.9200 - accuracy: 0.2883 - val_loss: 4.5576 - val_accuracy: 0.1824\n",
      "Epoch 31/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.9921 - accuracy: 0.2709 - val_loss: 159696.4188 - val_accuracy: 0.1119\n",
      "Epoch 32/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.8368 - accuracy: 0.3000 - val_loss: 2.7463 - val_accuracy: 0.3258\n",
      "Epoch 33/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.8527 - accuracy: 0.2812 - val_loss: 6097.5872 - val_accuracy: 0.0390\n",
      "Epoch 34/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.8032 - accuracy: 0.2953 - val_loss: 3.0492 - val_accuracy: 0.2302\n",
      "Epoch 35/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.7188 - accuracy: 0.3215 - val_loss: 3.8690 - val_accuracy: 0.1170\n",
      "Epoch 36/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.7389 - accuracy: 0.3187 - val_loss: 2.5570 - val_accuracy: 0.3333\n",
      "Epoch 37/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.7052 - accuracy: 0.3203 - val_loss: 5.5853 - val_accuracy: 0.2616\n",
      "Epoch 38/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.7118 - accuracy: 0.3023 - val_loss: 2.4115 - val_accuracy: 0.3937\n",
      "Epoch 39/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.6358 - accuracy: 0.3436 - val_loss: 780.1193 - val_accuracy: 0.1119\n",
      "Epoch 40/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.6284 - accuracy: 0.3422 - val_loss: 6.2430 - val_accuracy: 0.2063\n",
      "Epoch 41/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.5284 - accuracy: 0.3344 - val_loss: 2.3220 - val_accuracy: 0.4151\n",
      "Epoch 42/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.5102 - accuracy: 0.3499 - val_loss: 2.3393 - val_accuracy: 0.3862\n",
      "Epoch 43/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.3803 - accuracy: 0.3969 - val_loss: 2.4528 - val_accuracy: 0.3597\n",
      "Epoch 44/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.4129 - accuracy: 0.3797 - val_loss: 2.6610 - val_accuracy: 0.2767\n",
      "Epoch 45/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.3941 - accuracy: 0.3930 - val_loss: 45.6789 - val_accuracy: 0.0201\n",
      "Epoch 46/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.4466 - accuracy: 0.4016 - val_loss: 8.6006 - val_accuracy: 0.1459\n",
      "Epoch 47/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.3559 - accuracy: 0.3926 - val_loss: 2.4052 - val_accuracy: 0.4050\n",
      "Epoch 48/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.3180 - accuracy: 0.4131 - val_loss: 2.1675 - val_accuracy: 0.4390\n",
      "Epoch 49/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.3049 - accuracy: 0.4203 - val_loss: 8822.9016 - val_accuracy: 0.0403\n",
      "Epoch 50/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.3161 - accuracy: 0.4242 - val_loss: 2.4693 - val_accuracy: 0.3434\n",
      "Epoch 51/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.2632 - accuracy: 0.4202 - val_loss: 2.1872 - val_accuracy: 0.4503\n",
      "Epoch 52/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.2356 - accuracy: 0.4539 - val_loss: 2.2905 - val_accuracy: 0.3874\n",
      "Epoch 53/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.2278 - accuracy: 0.4414 - val_loss: 1.9395 - val_accuracy: 0.5396\n",
      "Epoch 54/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.2409 - accuracy: 0.4523 - val_loss: 1.9990 - val_accuracy: 0.5472\n",
      "Epoch 55/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.1946 - accuracy: 0.4487 - val_loss: 2.2140 - val_accuracy: 0.4252\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 105ms/step - loss: 2.2407 - accuracy: 0.4492 - val_loss: 2.1407 - val_accuracy: 0.4767\n",
      "Epoch 57/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.1853 - accuracy: 0.4668 - val_loss: 2.1135 - val_accuracy: 0.4767\n",
      "Epoch 58/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.2715 - accuracy: 0.4742 - val_loss: 2.0819 - val_accuracy: 0.4780\n",
      "Epoch 59/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.1907 - accuracy: 0.4727 - val_loss: 1.8161 - val_accuracy: 0.5736\n",
      "Epoch 60/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.0904 - accuracy: 0.5219 - val_loss: 3.0330 - val_accuracy: 0.2956\n",
      "Epoch 61/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0815 - accuracy: 0.5000 - val_loss: 2.0456 - val_accuracy: 0.4528\n",
      "Epoch 62/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0992 - accuracy: 0.4906 - val_loss: 1.9610 - val_accuracy: 0.5648\n",
      "Epoch 63/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.1169 - accuracy: 0.5063 - val_loss: 2.2019 - val_accuracy: 0.4579\n",
      "Epoch 64/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.2199 - accuracy: 0.5055 - val_loss: 3.6733 - val_accuracy: 0.2528\n",
      "Epoch 65/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.1132 - accuracy: 0.5297 - val_loss: 1.9614 - val_accuracy: 0.5723\n",
      "Epoch 66/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 2.0695 - accuracy: 0.5316 - val_loss: 2.0122 - val_accuracy: 0.5182\n",
      "Epoch 67/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0155 - accuracy: 0.5570 - val_loss: 1.7448 - val_accuracy: 0.6302\n",
      "Epoch 68/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.9792 - accuracy: 0.5616 - val_loss: 2.0642 - val_accuracy: 0.5233\n",
      "Epoch 69/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.9725 - accuracy: 0.5617 - val_loss: 1.6207 - val_accuracy: 0.6780\n",
      "Epoch 70/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.9611 - accuracy: 0.5600 - val_loss: 2.0885 - val_accuracy: 0.4994\n",
      "Epoch 71/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.9563 - accuracy: 0.5664 - val_loss: 5.1792 - val_accuracy: 0.1346\n",
      "Epoch 72/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0028 - accuracy: 0.5531 - val_loss: 1.7381 - val_accuracy: 0.6730\n",
      "Epoch 73/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0355 - accuracy: 0.5406 - val_loss: 4.5656 - val_accuracy: 0.5774\n",
      "Epoch 74/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0897 - accuracy: 0.5578 - val_loss: 1.8257 - val_accuracy: 0.6843\n",
      "Epoch 75/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 2.0543 - accuracy: 0.5586 - val_loss: 1.7009 - val_accuracy: 0.6906\n",
      "Epoch 76/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.9239 - accuracy: 0.6090 - val_loss: 1.6778 - val_accuracy: 0.6491\n",
      "Epoch 77/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.9240 - accuracy: 0.6141 - val_loss: 1.5576 - val_accuracy: 0.7094\n",
      "Epoch 78/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.8926 - accuracy: 0.5916 - val_loss: 1.9097 - val_accuracy: 0.5711\n",
      "Epoch 79/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.9422 - accuracy: 0.5945 - val_loss: 1.5676 - val_accuracy: 0.7233\n",
      "Epoch 80/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.9073 - accuracy: 0.5956 - val_loss: 1.5197 - val_accuracy: 0.7031\n",
      "Epoch 81/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.8713 - accuracy: 0.5979 - val_loss: 1.5935 - val_accuracy: 0.7308\n",
      "Epoch 82/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.8262 - accuracy: 0.6311 - val_loss: 1.5566 - val_accuracy: 0.7094\n",
      "Epoch 83/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7903 - accuracy: 0.6224 - val_loss: 4.2048 - val_accuracy: 0.7145\n",
      "Epoch 84/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7419 - accuracy: 0.6627 - val_loss: 1.4952 - val_accuracy: 0.7447\n",
      "Epoch 85/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7983 - accuracy: 0.6344 - val_loss: 1.6303 - val_accuracy: 0.6654\n",
      "Epoch 86/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7907 - accuracy: 0.6461 - val_loss: 1.5247 - val_accuracy: 0.7308\n",
      "Epoch 87/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.8197 - accuracy: 0.6352 - val_loss: 1.4237 - val_accuracy: 0.7560\n",
      "Epoch 88/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7314 - accuracy: 0.6445 - val_loss: 1.6859 - val_accuracy: 0.7195\n",
      "Epoch 89/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7490 - accuracy: 0.6547 - val_loss: 2.7703 - val_accuracy: 0.6088\n",
      "Epoch 90/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7676 - accuracy: 0.6430 - val_loss: 1.5039 - val_accuracy: 0.7358\n",
      "Epoch 91/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7495 - accuracy: 0.6664 - val_loss: 1.4247 - val_accuracy: 0.7308\n",
      "Epoch 92/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7391 - accuracy: 0.6635 - val_loss: 1.4368 - val_accuracy: 0.7786\n",
      "Epoch 93/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.6804 - accuracy: 0.6969 - val_loss: 2.2358 - val_accuracy: 0.6013\n",
      "Epoch 94/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7675 - accuracy: 0.6773 - val_loss: 1.4182 - val_accuracy: 0.7660\n",
      "Epoch 95/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7562 - accuracy: 0.6825 - val_loss: 1.4340 - val_accuracy: 0.7358\n",
      "Epoch 96/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7428 - accuracy: 0.6711 - val_loss: 1.4450 - val_accuracy: 0.7761\n",
      "Epoch 97/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.6828 - accuracy: 0.6953 - val_loss: 1.3660 - val_accuracy: 0.7774\n",
      "Epoch 98/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7191 - accuracy: 0.6969 - val_loss: 1.3916 - val_accuracy: 0.7950\n",
      "Epoch 99/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7489 - accuracy: 0.6797 - val_loss: 1.3926 - val_accuracy: 0.7962\n",
      "Epoch 100/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7580 - accuracy: 0.6805 - val_loss: 8.4103 - val_accuracy: 0.3962\n",
      "Epoch 101/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.8084 - accuracy: 0.6651 - val_loss: 1.7065 - val_accuracy: 0.7736\n",
      "Epoch 102/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7834 - accuracy: 0.6797 - val_loss: 1.4184 - val_accuracy: 0.7975\n",
      "Epoch 103/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.8235 - accuracy: 0.6773 - val_loss: 2.5416 - val_accuracy: 0.5396\n",
      "Epoch 104/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7350 - accuracy: 0.7039 - val_loss: 1.4149 - val_accuracy: 0.8013\n",
      "Epoch 105/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.7209 - accuracy: 0.7000 - val_loss: 2.1051 - val_accuracy: 0.5937\n",
      "Epoch 106/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.6863 - accuracy: 0.7220 - val_loss: 1.4767 - val_accuracy: 0.7811\n",
      "Epoch 107/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5944 - accuracy: 0.7622 - val_loss: 1.3628 - val_accuracy: 0.8138\n",
      "Epoch 108/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.7016 - accuracy: 0.7085 - val_loss: 3.9240 - val_accuracy: 0.4214\n",
      "Epoch 109/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5958 - accuracy: 0.7378 - val_loss: 1.4190 - val_accuracy: 0.8013\n",
      "Epoch 110/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5997 - accuracy: 0.7375 - val_loss: 1.3362 - val_accuracy: 0.8176\n",
      "Epoch 111/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5745 - accuracy: 0.7322 - val_loss: 1.2306 - val_accuracy: 0.8491\n",
      "Epoch 112/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5777 - accuracy: 0.7430 - val_loss: 1.3244 - val_accuracy: 0.7912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5048 - accuracy: 0.7539 - val_loss: 1.2915 - val_accuracy: 0.8239\n",
      "Epoch 114/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5049 - accuracy: 0.7480 - val_loss: 1.3873 - val_accuracy: 0.7937\n",
      "Epoch 115/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5697 - accuracy: 0.7338 - val_loss: 1.3082 - val_accuracy: 0.8289\n",
      "Epoch 116/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.6384 - accuracy: 0.7006 - val_loss: 1.3678 - val_accuracy: 0.7849\n",
      "Epoch 117/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5049 - accuracy: 0.7602 - val_loss: 1.4348 - val_accuracy: 0.7673\n",
      "Epoch 118/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5823 - accuracy: 0.7367 - val_loss: 1.3137 - val_accuracy: 0.8138\n",
      "Epoch 119/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5635 - accuracy: 0.7453 - val_loss: 1.4310 - val_accuracy: 0.8277\n",
      "Epoch 120/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5389 - accuracy: 0.7555 - val_loss: 1.2161 - val_accuracy: 0.8654\n",
      "Epoch 121/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4949 - accuracy: 0.7930 - val_loss: 13217.6819 - val_accuracy: 0.0403\n",
      "Epoch 122/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5475 - accuracy: 0.7536 - val_loss: 1.2679 - val_accuracy: 0.8491\n",
      "Epoch 123/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5840 - accuracy: 0.7480 - val_loss: 1.3592 - val_accuracy: 0.8201\n",
      "Epoch 124/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5894 - accuracy: 0.7516 - val_loss: 1.2921 - val_accuracy: 0.8604\n",
      "Epoch 125/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5588 - accuracy: 0.7607 - val_loss: 1.2363 - val_accuracy: 0.8667\n",
      "Epoch 126/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.5174 - accuracy: 0.7773 - val_loss: 1.2479 - val_accuracy: 0.8566\n",
      "Epoch 127/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4739 - accuracy: 0.7923 - val_loss: 1.5772 - val_accuracy: 0.8025\n",
      "Epoch 128/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4871 - accuracy: 0.7672 - val_loss: 1.2329 - val_accuracy: 0.8503\n",
      "Epoch 129/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4553 - accuracy: 0.7688 - val_loss: 1.8937 - val_accuracy: 0.8503\n",
      "Epoch 130/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4158 - accuracy: 0.7883 - val_loss: 1.1517 - val_accuracy: 0.8491\n",
      "Epoch 131/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4389 - accuracy: 0.7788 - val_loss: 1.2327 - val_accuracy: 0.8579\n",
      "Epoch 132/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4075 - accuracy: 0.7970 - val_loss: 1.1588 - val_accuracy: 0.8629\n",
      "Epoch 133/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4388 - accuracy: 0.8009 - val_loss: 1.1336 - val_accuracy: 0.8679\n",
      "Epoch 134/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4284 - accuracy: 0.7852 - val_loss: 1.2306 - val_accuracy: 0.8654\n",
      "Epoch 135/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4751 - accuracy: 0.7719 - val_loss: 1.2285 - val_accuracy: 0.8591\n",
      "Epoch 136/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4425 - accuracy: 0.7867 - val_loss: 1.1574 - val_accuracy: 0.8767\n",
      "Epoch 137/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4971 - accuracy: 0.7758 - val_loss: 1.2247 - val_accuracy: 0.8805\n",
      "Epoch 138/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5140 - accuracy: 0.7937 - val_loss: 1.2515 - val_accuracy: 0.8717\n",
      "Epoch 139/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4495 - accuracy: 0.8041 - val_loss: 1.1292 - val_accuracy: 0.8843\n",
      "Epoch 140/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4231 - accuracy: 0.8031 - val_loss: 1.2129 - val_accuracy: 0.8667\n",
      "Epoch 141/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4453 - accuracy: 0.8102 - val_loss: 1.1691 - val_accuracy: 0.8918\n",
      "Epoch 142/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3753 - accuracy: 0.8156 - val_loss: 1.1416 - val_accuracy: 0.8918\n",
      "Epoch 143/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3701 - accuracy: 0.8117 - val_loss: 1.5714 - val_accuracy: 0.8075\n",
      "Epoch 144/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3517 - accuracy: 0.8188 - val_loss: 1.1458 - val_accuracy: 0.8931\n",
      "Epoch 145/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3738 - accuracy: 0.8227 - val_loss: 1.2332 - val_accuracy: 0.8642\n",
      "Epoch 146/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4037 - accuracy: 0.8065 - val_loss: 1.2826 - val_accuracy: 0.8403\n",
      "Epoch 147/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4779 - accuracy: 0.8128 - val_loss: 1.8902 - val_accuracy: 0.7686\n",
      "Epoch 148/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4386 - accuracy: 0.8250 - val_loss: 1.1971 - val_accuracy: 0.8943\n",
      "Epoch 149/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4051 - accuracy: 0.8349 - val_loss: 1.2103 - val_accuracy: 0.8780\n",
      "Epoch 150/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4809 - accuracy: 0.8062 - val_loss: 1.7447 - val_accuracy: 0.7849\n",
      "Epoch 151/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5199 - accuracy: 0.8219 - val_loss: 1.2721 - val_accuracy: 0.8918\n",
      "Epoch 152/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.5440 - accuracy: 0.8023 - val_loss: 1.2432 - val_accuracy: 0.8830\n",
      "Epoch 153/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4127 - accuracy: 0.8320 - val_loss: 1.1248 - val_accuracy: 0.9094\n",
      "Epoch 154/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.3927 - accuracy: 0.8199 - val_loss: 92.2177 - val_accuracy: 0.3925\n",
      "Epoch 155/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3155 - accuracy: 0.8438 - val_loss: 1.0727 - val_accuracy: 0.9132\n",
      "Epoch 156/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2449 - accuracy: 0.8492 - val_loss: 1.0278 - val_accuracy: 0.9245\n",
      "Epoch 157/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3014 - accuracy: 0.8438 - val_loss: 1.0857 - val_accuracy: 0.9019\n",
      "Epoch 158/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2568 - accuracy: 0.8461 - val_loss: 24.9372 - val_accuracy: 0.8893\n",
      "Epoch 159/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3043 - accuracy: 0.8336 - val_loss: 1.1309 - val_accuracy: 0.8931\n",
      "Epoch 160/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2694 - accuracy: 0.8531 - val_loss: 23.1478 - val_accuracy: 0.7484\n",
      "Epoch 161/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3613 - accuracy: 0.8211 - val_loss: 1.1905 - val_accuracy: 0.8969\n",
      "Epoch 162/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3476 - accuracy: 0.8367 - val_loss: 1.7354 - val_accuracy: 0.9107\n",
      "Epoch 163/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3349 - accuracy: 0.8428 - val_loss: 2.1432 - val_accuracy: 0.8956\n",
      "Epoch 164/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2702 - accuracy: 0.8641 - val_loss: 1.2735 - val_accuracy: 0.8931\n",
      "Epoch 165/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2208 - accuracy: 0.8610 - val_loss: 1.6369 - val_accuracy: 0.9094\n",
      "Epoch 166/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2236 - accuracy: 0.8586 - val_loss: 8.1216 - val_accuracy: 0.8792\n",
      "Epoch 167/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.3134 - accuracy: 0.8483 - val_loss: 34.5690 - val_accuracy: 0.9006\n",
      "Epoch 168/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2823 - accuracy: 0.8555 - val_loss: 1.0491 - val_accuracy: 0.9182\n",
      "Epoch 169/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3452 - accuracy: 0.8344 - val_loss: 1.0732 - val_accuracy: 0.9208\n",
      "Epoch 170/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3302 - accuracy: 0.8508 - val_loss: 1.3570 - val_accuracy: 0.8528\n",
      "Epoch 171/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2873 - accuracy: 0.8500 - val_loss: 1.0848 - val_accuracy: 0.9195\n",
      "Epoch 172/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2723 - accuracy: 0.8656 - val_loss: 1.1187 - val_accuracy: 0.9182\n",
      "Epoch 173/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2792 - accuracy: 0.8373 - val_loss: 1.0547 - val_accuracy: 0.9145\n",
      "Epoch 174/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1941 - accuracy: 0.8547 - val_loss: 1.0115 - val_accuracy: 0.9308\n",
      "Epoch 175/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1323 - accuracy: 0.8863 - val_loss: 1.0416 - val_accuracy: 0.9094\n",
      "Epoch 176/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1394 - accuracy: 0.8766 - val_loss: 0.9670 - val_accuracy: 0.9371\n",
      "Epoch 177/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2036 - accuracy: 0.8570 - val_loss: 1.1489 - val_accuracy: 0.8855\n",
      "Epoch 178/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3160 - accuracy: 0.8391 - val_loss: 1.1797 - val_accuracy: 0.8994\n",
      "Epoch 179/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.4402 - accuracy: 0.8175 - val_loss: 1.4051 - val_accuracy: 0.8415\n",
      "Epoch 180/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3933 - accuracy: 0.8469 - val_loss: 1.1494 - val_accuracy: 0.9195\n",
      "Epoch 181/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3605 - accuracy: 0.8523 - val_loss: 1.0994 - val_accuracy: 0.9233\n",
      "Epoch 182/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.3020 - accuracy: 0.8697 - val_loss: 86683.4684 - val_accuracy: 0.0377\n",
      "Epoch 183/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3150 - accuracy: 0.8484 - val_loss: 1.1064 - val_accuracy: 0.9107\n",
      "Epoch 184/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.3313 - accuracy: 0.8610 - val_loss: 1.0568 - val_accuracy: 0.9245\n",
      "Epoch 185/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2463 - accuracy: 0.8727 - val_loss: 1.0320 - val_accuracy: 0.9283\n",
      "Epoch 186/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2206 - accuracy: 0.8633 - val_loss: 1.0060 - val_accuracy: 0.9346\n",
      "Epoch 187/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1701 - accuracy: 0.8799 - val_loss: 0.9821 - val_accuracy: 0.9384\n",
      "Epoch 188/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2159 - accuracy: 0.8586 - val_loss: 0.9700 - val_accuracy: 0.9371\n",
      "Epoch 189/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1506 - accuracy: 0.8847 - val_loss: 1.0602 - val_accuracy: 0.9333\n",
      "Epoch 190/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2147 - accuracy: 0.8648 - val_loss: 1.0322 - val_accuracy: 0.9321\n",
      "Epoch 191/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2234 - accuracy: 0.8758 - val_loss: 0.9939 - val_accuracy: 0.9409\n",
      "Epoch 192/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2519 - accuracy: 0.8602 - val_loss: 1.0210 - val_accuracy: 0.9384\n",
      "Epoch 193/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2446 - accuracy: 0.8609 - val_loss: 17.8366 - val_accuracy: 0.9371\n",
      "Epoch 194/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2489 - accuracy: 0.8665 - val_loss: 1.1113 - val_accuracy: 0.9107\n",
      "Epoch 195/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2466 - accuracy: 0.8712 - val_loss: 60.1717 - val_accuracy: 0.7799\n",
      "Epoch 196/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2207 - accuracy: 0.8784 - val_loss: 1.0254 - val_accuracy: 0.9358\n",
      "Epoch 197/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1689 - accuracy: 0.8836 - val_loss: 1.0302 - val_accuracy: 0.9195\n",
      "Epoch 198/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2082 - accuracy: 0.8768 - val_loss: 1.1462 - val_accuracy: 0.8956\n",
      "Epoch 199/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1937 - accuracy: 0.8781 - val_loss: 1.2571 - val_accuracy: 0.9447\n",
      "Epoch 200/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.2434 - accuracy: 0.8555 - val_loss: 1.0379 - val_accuracy: 0.9447\n",
      "Epoch 201/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2616 - accuracy: 0.8844 - val_loss: 1.0318 - val_accuracy: 0.9522\n",
      "Epoch 202/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1992 - accuracy: 0.8844 - val_loss: 0.9852 - val_accuracy: 0.9547\n",
      "Epoch 203/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1584 - accuracy: 0.8934 - val_loss: 64.3878 - val_accuracy: 0.1044\n",
      "Epoch 204/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1219 - accuracy: 0.9016 - val_loss: 0.9438 - val_accuracy: 0.9535\n",
      "Epoch 205/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1447 - accuracy: 0.8875 - val_loss: 0.9557 - val_accuracy: 0.9459\n",
      "Epoch 206/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1552 - accuracy: 0.8898 - val_loss: 0.9450 - val_accuracy: 0.9572\n",
      "Epoch 207/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0952 - accuracy: 0.9000 - val_loss: 0.8892 - val_accuracy: 0.9673\n",
      "Epoch 208/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1446 - accuracy: 0.8847 - val_loss: 0.9171 - val_accuracy: 0.9585\n",
      "Epoch 209/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1209 - accuracy: 0.8945 - val_loss: 0.9270 - val_accuracy: 0.9610\n",
      "Epoch 210/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1250 - accuracy: 0.8934 - val_loss: 0.8923 - val_accuracy: 0.9799\n",
      "Epoch 211/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1586 - accuracy: 0.8859 - val_loss: 0.9340 - val_accuracy: 0.9610\n",
      "Epoch 212/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1471 - accuracy: 0.8965 - val_loss: 0.9498 - val_accuracy: 0.9484\n",
      "Epoch 213/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1475 - accuracy: 0.8886 - val_loss: 1.0071 - val_accuracy: 0.9409\n",
      "Epoch 214/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1649 - accuracy: 0.8852 - val_loss: 1.0117 - val_accuracy: 0.9421\n",
      "Epoch 215/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1407 - accuracy: 0.8984 - val_loss: 1.1245 - val_accuracy: 0.9057\n",
      "Epoch 216/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1757 - accuracy: 0.8898 - val_loss: 1.0208 - val_accuracy: 0.9396\n",
      "Epoch 217/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2055 - accuracy: 0.8789 - val_loss: 0.9877 - val_accuracy: 0.9585\n",
      "Epoch 218/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2076 - accuracy: 0.8852 - val_loss: 1.0252 - val_accuracy: 0.9472\n",
      "Epoch 219/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1418 - accuracy: 0.9039 - val_loss: 0.9919 - val_accuracy: 0.9447\n",
      "Epoch 220/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1641 - accuracy: 0.8930 - val_loss: 1.4840 - val_accuracy: 0.9170\n",
      "Epoch 221/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1980 - accuracy: 0.8852 - val_loss: 1.0346 - val_accuracy: 0.9421\n",
      "Epoch 222/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1909 - accuracy: 0.8965 - val_loss: 1.1356 - val_accuracy: 0.9459\n",
      "Epoch 223/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1626 - accuracy: 0.9125 - val_loss: 0.9915 - val_accuracy: 0.9484\n",
      "Epoch 224/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1916 - accuracy: 0.8910 - val_loss: 0.9815 - val_accuracy: 0.9597\n",
      "Epoch 225/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2305 - accuracy: 0.8875 - val_loss: 1.0073 - val_accuracy: 0.9635\n",
      "Epoch 226/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.3295 - accuracy: 0.8697 - val_loss: 1.1757 - val_accuracy: 0.9308\n",
      "Epoch 227/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4027 - accuracy: 0.8719 - val_loss: 1.2550 - val_accuracy: 0.9283\n",
      "Epoch 228/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.4125 - accuracy: 0.8776 - val_loss: 1.1719 - val_accuracy: 0.9535\n",
      "Epoch 229/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.3394 - accuracy: 0.8984 - val_loss: 40.5684 - val_accuracy: 0.9748\n",
      "Epoch 230/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.2550 - accuracy: 0.9000 - val_loss: 1.0518 - val_accuracy: 0.9623\n",
      "Epoch 231/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1986 - accuracy: 0.9115 - val_loss: 1.0668 - val_accuracy: 0.9711\n",
      "Epoch 232/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1678 - accuracy: 0.9102 - val_loss: 1.2314 - val_accuracy: 0.9597\n",
      "Epoch 233/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1351 - accuracy: 0.9076 - val_loss: 2.3054 - val_accuracy: 0.9447\n",
      "Epoch 234/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0727 - accuracy: 0.9219 - val_loss: 0.8940 - val_accuracy: 0.9648\n",
      "Epoch 235/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.0643 - accuracy: 0.9147 - val_loss: 0.8834 - val_accuracy: 0.9824\n",
      "Epoch 236/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0708 - accuracy: 0.9125 - val_loss: 2.1089 - val_accuracy: 0.9472\n",
      "Epoch 237/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1030 - accuracy: 0.9125 - val_loss: 0.8889 - val_accuracy: 0.9774\n",
      "Epoch 238/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0986 - accuracy: 0.9047 - val_loss: 1.0031 - val_accuracy: 0.9358\n",
      "Epoch 239/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0971 - accuracy: 0.9203 - val_loss: 0.8950 - val_accuracy: 0.9811\n",
      "Epoch 240/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1512 - accuracy: 0.8973 - val_loss: 65.2969 - val_accuracy: 0.3396\n",
      "Epoch 241/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1537 - accuracy: 0.9123 - val_loss: 0.9166 - val_accuracy: 0.9811\n",
      "Epoch 242/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1178 - accuracy: 0.9139 - val_loss: 0.9838 - val_accuracy: 0.9459\n",
      "Epoch 243/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0709 - accuracy: 0.9141 - val_loss: 0.9116 - val_accuracy: 0.9698\n",
      "Epoch 244/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0557 - accuracy: 0.9242 - val_loss: 0.8758 - val_accuracy: 0.9761\n",
      "Epoch 245/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.0542 - accuracy: 0.9147 - val_loss: 0.9439 - val_accuracy: 0.9447\n",
      "Epoch 246/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1069 - accuracy: 0.9005 - val_loss: 0.9511 - val_accuracy: 0.9522\n",
      "Epoch 247/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.1240 - accuracy: 0.9131 - val_loss: 0.9532 - val_accuracy: 0.9761\n",
      "Epoch 248/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.1506 - accuracy: 0.9102 - val_loss: 0.9465 - val_accuracy: 0.9774\n",
      "Epoch 249/250\n",
      "40/40 [==============================] - 4s 104ms/step - loss: 1.0630 - accuracy: 0.9273 - val_loss: 0.8881 - val_accuracy: 0.9811\n",
      "Epoch 250/250\n",
      "40/40 [==============================] - 4s 105ms/step - loss: 1.0615 - accuracy: 0.9258 - val_loss: 0.8803 - val_accuracy: 0.9799\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Test loss: 2.1359201033910113\n",
      "Test accuracy: 0.72642\n",
      "echo this is the end ***\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(train_dataset, steps_per_epoch=40,validation_data=valid_dataset, epochs=250,shuffle=True)\n",
    "\n",
    "\n",
    "score = model.evaluate(test_dataset, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n",
    "print(\"echo this is the end ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
